/*
 * decaffeinate suggestions:
 * DS101: Remove unnecessary use of Array.from
 * DS102: Remove unnecessary code created because of implicit returns
 * DS205: Consider reworking code to avoid use of IIFEs
 * DS207: Consider shorter variations of null checks
 * Full docs: https://github.com/decaffeinate/decaffeinate/blob/master/docs/suggestions.md
 */
/*
 * ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 * SPDX-License-Identifier: Apache-2.0
 * ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 */

import fs from 'fs';
import path from 'path';
import mkdirp from 'mkdirp';
import rimraf from 'rimraf';
import util from 'util';
import crypto from 'crypto';
import AWS from 'aws-sdk';
import uuid from 'uuid';
import { handle } from './aws-config';
import { exec, execSync } from 'child_process';
import zip from 'adm-zip';
import { ensureLambdaIAMRole } from './iam-roles';

const debug = require('debug')('litexa-deploy-lambda');

const writeFilePromise = util.promisify(fs.writeFile);
const readFilePromise = util.promisify(fs.readFile);

const SupportedOS = {
  LINUX: 'linux',
  OSX: 'darwin',
  WIN: 'win32'
};

const writeFileIfDifferent = (filename, contents) => readFilePromise(filename, 'utf8')
.catch(err => // fine if we can't read it, we'll assume we have to write
Promise.resolve()).then(function(fileContents) {
  if (contents === fileContents) {
    return Promise.resolve(false);
  } else {
    return writeFilePromise(filename, contents, 'utf8').then(() => Promise.resolve(true));
  }
});

// TODO: Used for unit testing. Can remove when refactoring code to be more modular and test friendly
//   as eval does reduce runtime performance, but this should mainly be in the build process
export function unitTestHelper(funcName) {
  const args = Array.prototype.slice.call(arguments);
  return eval(funcName)
  .apply(this, args.slice(1));
};

export function deploy(context, logger) {
  logger.log("deploying lambda");

  context.lambdaDeployStart = new Date;
  const lambdaContext = {
    codeRoot: path.join(context.deployRoot, 'lambda'),
    litexaRoot: path.join(context.projectRoot, 'litexa')
  };

  const call = func => func(context, logger, lambdaContext);

  return call(preamble)
  .then(function() {
    // all of this can happen at the same time
    const step1 = [
      call(writeReadme),
      call(writeSkillJS),
      call(copyNodeModules),
      call(ensureDynamoTable)
    ];

    return Promise.all(step1);}).then(() => call(packZipFile)).then(() => call(createZipSHA256)).then(() => call(getLambdaConfig)).then(() => call(updateLambdaConfig)
  .then(() => call(updateLambdaCode))).catch(function(err) {
    if (err.code !== 'ResourceNotFoundException') {
      throw err;
    }
    // doesn't exist, make it
    return call(createLambda);}).then(() => call(checkLambdaQualifier)).then(() => call(checkLambdaPermissions)).then(() => call(changeCloudwatchRetentionPolicy)).then(() => call(checkForAssetsRoot)).then(() => call(endLambdaDeployment)).catch(function(err) {
    logger.error("lambda deployment failed");
    throw err;
  });
};

var preamble = (context, logger, lambdaContext) => new Promise(function(resolve, reject) {
  try {
    handle(context, logger, AWS);

    mkdirp.sync(lambdaContext.codeRoot);

    lambdaContext.lambda = new AWS.Lambda;

    context.lambdaName = [
      context.projectInfo.name,
      context.projectInfo.variant,
      "litexa",
      "handler"
    ].join('_');

    // the alias we're going to deploy to
    lambdaContext.qualifier = "release-" + context.artifacts.currentVersion;

  } catch (err) {
    return reject(err);
  }

  return resolve();
});


var writeReadme = function(context, logger, lambdaContext) {
  // readme
  const readme = `\
This lambda was generated by the litexa package
and uploaded using the @litexa/deploy-aws package\
`;

  const filename = path.join(lambdaContext.codeRoot,'readme.md');
  return writeFileIfDifferent(filename, readme)
  .then(function(wrote) {
    if (wrote) {
      return logger.log("wrote readme");
    }
  });
};


var writeSkillJS = function(context, logger, lambdaContext) {
  const code = context.skill.toLambda();

  const filename = path.join(lambdaContext.codeRoot,'index.js');
  return writeFileIfDifferent(filename, code)
  .then(function(wrote) {
    if (wrote) {
      return logger.log("wrote index.js");
    }
  });
};


var copyNodeModules = function(context, logger, lambdaContext) {
  const sourceDir = path.join(context.skill.projectInfo.litexaRoot, 'node_modules');
  const targetDir = path.join(lambdaContext.codeRoot);
  const modulesCache = path.join(context.deployRoot, "modules.cache");

  logger.log("considering node_modules");

  // check to see if any files appear to be modified since the last time
  // we did this
  const msSinceLastCopy = context.localCache.millisecondsSince('copiedNodeModules');
  const needsCopy = function(location) {
    if (!fs.existsSync(modulesCache)) {
      return true;
    }
    if (msSinceLastCopy == null) {
      return true;
    }

    const secondInMillis = 1000;
    const secondsSinceLastCopy = Math.ceil(msSinceLastCopy / secondInMillis);


    if (process.platform === SupportedOS.WIN) {
      // WINCOMPAT - find the first thing that has changed since the last copy. Could use a faster
      //   algorithm to find the last modified file more quickly.
      const fileList = fs.readdirSync(sourceDir)
        .map(v => ({
        name: v,
        time: fs.statSync(path.join(sourceDir, v)).mtime.getTime()
      }));

      // Grabs the timestamp of the most recently modified file from folder
      const reducer = function(prev, curr) { if (prev.time > curr.time) { return prev; } else { return curr; } };
      const lastModifiedTime = fileList.reduce(reducer, 0)
        .time;

      return lastModifiedTime > ((new Date).getTime() - (secondsSinceLastCopy * secondInMillis));
    } else {
      const result = execSync(`find -L ${sourceDir} -type f -atime -${secondsSinceLastCopy}s | head -n 1`);
      return result.length > 0;
    }
  };

  if (!needsCopy(sourceDir)) {
    logger.log("node modules appear to be up to date");
    return Promise.resolve();
  }

  const packageJSONPath = path.join(context.skill.projectInfo.litexaRoot, 'package.json');
  if (!fs.existsSync(packageJSONPath)) {
    logger.log(`no package.json found at ${packageJSONPath}, skipping node_modules`);
    return Promise.resolve();
  }

  const nodeModulesPath = path.join(context.skill.projectInfo.litexaRoot, 'node_modules');
  if (!fs.existsSync(nodeModulesPath)) {
    throw new Error(`no node_modules found at ${nodeModulesPath}, but we did \
see ${packageJSONPath}. Aborting for now. Did you perhaps miss running \
\`npm install\` from your litexa directory?`
    );
    return Promise.resolve();
  }

  return new Promise(function(resolve, reject) {
    const startTime = new Date;

    let execCmd = `rsync -crt --copy-links --delete --exclude '*.git' ${sourceDir} ${targetDir}`;
    if (process.platform === SupportedOS.WIN) {
      // WINCOMPAT - Windows uses robocopy in place of rsync to ensure files get replicated to destination
      execCmd = `robocopy  ${sourceDir} ${targetDir} /mir /copy:DAT /sl /xf \"*.git\" /r:3 /w:4`;
    }

    return exec(execCmd, function(err, stdout, stderr) {
      if (stdout) { logger.log("rsync: \n" + stdout); }
      const deltaTime = (new Date) - startTime;
      fs.writeFileSync(modulesCache, '');
      logger.log(`synchronized node_modules in ${deltaTime}ms`);
      if (err != null) {
        return reject(err);
      } else if (stderr) {
        logger.log(stderr);
        return reject(err);
      } else {
        context.localCache.saveTimestamp('copiedNodeModules');
        return resolve();
      }
    });
  });
};


var packZipFile = (context, logger, lambdaContext) => new Promise(function(resolve, reject) {
  logger.log("beginning zip archive");
  const zipStart = new Date;

  lambdaContext.zipFilename = path.join(context.deployRoot, 'lambda.zip');

  const lambdaSource = path.join(context.deployRoot,'lambda');
  debug(`source directory: ${lambdaSource}`);

  const zipFileCreationLogging = function(err, stdout, stderr) {
    logger.log(`Platform: ${process.platform}`);
    if (process.platform === SupportedOS.WIN) {
      // WINCOMPAT - deletes old zip and creates new zip. There may be a faster way to zip on Windows.
      const zipper = new zip;
      zipper.addLocalFolder(lambdaSource);
      zipper.writeZip(lambdaContext.zipFilename);
    }

    let zipLog = path.join(context.deployRoot, 'zip.out.log');
    fs.writeFileSync(zipLog, stdout);
    zipLog = path.join(context.deployRoot, 'zip.err.log');
    fs.writeFileSync(zipLog, "" + err + stderr);
    if (err != null) {
      logger.error(err);
      throw "failed to zip lambda";
    }
    const deltaTime = (new Date) - zipStart;
    logger.log(`zip archiving complete in ${deltaTime}ms`);

    return resolve();
  };

  if (process.platform === SupportedOS.WIN) {
    // WINCOMPAT - using rimraf instead of rm -f for compatability
    return rimraf('../data.zip', zipFileCreationLogging);
  } else {
    return exec("rm -f ../data.zip && zip -rX ../lambda.zip *",
      {
        cwd: lambdaSource,
        maxBuffer: 1024 * 500
      },
      zipFileCreationLogging);
  }
});


var createZipSHA256 = (context, logger, lambdaContext) => new Promise(function(resolve, reject) {
  const shasum = crypto.createHash('sha256');
  return fs.createReadStream(lambdaContext.zipFilename)
  .on("data", chunk => shasum.update(chunk)).on("end", function() {
    lambdaContext.zipSHA256 = shasum.digest('base64');
    logger.log(`zip SHA: ${lambdaContext.zipSHA256}`);
    return resolve();
  }).on("error", err => reject(err));
});


var getLambdaConfig = function(context, logger, lambdaContext) {
  if (context.localCache.lessThanSince('lambdaUpdated', 30)) {
    // it's ok to skip this during iteration, so do it every half hour
    lambdaContext.deployedSHA256 = context.localCache.getHash('lambdaSHA256');
    logger.log(`skipping Lambda ${context.lambdaName} configuration check`);
    return Promise.resolve();
  }

  logger.log(`fetching Lambda ${context.lambdaName} configuration`);

  const params =
    {FunctionName: context.lambdaName};

  return lambdaContext.lambda.getFunctionConfiguration(params).promise()
  .then(function(data) {
    logger.log("fetched Lambda configuration");
    lambdaContext.deployedSHA256 = data.CodeSha256;
    lambdaContext.deployedLambdaConfig = data;
    setLambdaARN(context, lambdaContext, data.FunctionArn);
    return Promise.resolve(data);
  });
};


var setLambdaARN = function(context, lambdaContext, newARN) {
  const aliasedARN = `${newARN}:${lambdaContext.qualifier}`;
  lambdaContext.baseARN = newARN;
  context.lambdaARN = aliasedARN;
  return context.artifacts.save('lambdaARN', aliasedARN);
};


const makeLambdaConfiguration = (context, logger) => ensureLambdaIAMRole(context, logger)
.then(function() {
  let loggingLevel = ['alpha', 'beta', 'gamma'].includes(context.projectInfo.variant) ?
    undefined
  :
    'terse';

  loggingLevel = 'terse';

  const config = {
    Description: `Litexa skill handler for project ${context.projectInfo.name}`,
    Handler: "index.handler", // exports.handler in index.js
    MemorySize: 256, // megabytes, mainly because this also means dedicated CPU
    Role: context.lambdaIAMRoleARN,
    Runtime: "nodejs10.x",
    Timeout: 10, // seconds
    Environment: {
      Variables: {
        variant: context.projectInfo.variant,
        loggingLevel,
        dynamoTableName: context.dynamoTableName,
        assetsRoot: context.artifacts.get('assets-root')
      }
    }
  };


  if (context.deploymentOptions.lambdaConfiguration != null) {
    // if this option is present, merge that object into the config, key by key
    var mergeValue = function( target, key, value, stringify ) {
      if (key in target) {
        if (typeof(target[key]) === 'object') {
          // recurse into objects
          if (typeof(value) !== 'object') {
            throw `value of key ${key} was expected to be an object in lambdaConfiguration, but was instead ${JSON.stringify(value)}`;
          }
          for (let k in value) {
            // variable value must be strings, so switch here
            const v = value[k];
            if (k === 'Variables') {
              stringify = true;
            }
            mergeValue(target[key], k, v, stringify);
          }
          return;
        }
      }

      if (stringify) {
        return target[key] = '' + value;
      } else {
        return target[key] = value;
      }
    };

    for (let k in context.deploymentOptions.lambdaConfiguration) {
      const v = context.deploymentOptions.lambdaConfiguration[k];
      mergeValue(config, k, v, false);
    }
  }

  debug("Lambda config: " + JSON.stringify(config, null, 2));

  return config;
});


var createLambda = function(context, logger, lambdaContext) {
  logger.log(`creating Lambda function ${context.lambdaName}`);

  let params = {
    Code: {
      ZipFile: fs.readFileSync(lambdaContext.zipFilename)
    },
    FunctionName: context.lambdaName,
    Publish: true,
    VpcConfig: {}
  };

  return makeLambdaConfiguration(context, logger)
  .then(function(lambdaConfig) {
    for (let k in lambdaConfig) {
      const v = lambdaConfig[k];
      params[k] = v;
    }
    return lambdaContext.lambda.createFunction(params).promise();}).then(function(data) {
    logger.verbose('create-function', data);
    logger.log(`creating LIVE alias for Lambda function ${context.lambdaName}`);
    lambdaContext.deployedSHA256 = data.CodeSha256;
    setLambdaARN(context, lambdaContext, data.FunctionArn);

    // create the live alias, to support easy
    // console based rollbacks in emergencies
    params = {
      FunctionName: context.lambdaName,
      FunctionVersion: '$LATEST',
      Name: 'LIVE',
      Description: 'Current live version, used to refer to this lambda by the Alexa skill. In an emergency, you can point this to an older version of the code.'
    };

    return lambdaContext.lambda.createAlias(params).promise();
  });
};

function updateLambdaConfig(context, logger, lambdaContext) {
  let needsUpdating = false;
  var matchObject = function(a, b) {
    if (b == null) {
      return needsUpdating = true;
    }
    return (() => {
      const result = [];
      for (let k in a) {
        const v = a[k];
        if (typeof(v) === 'object') {
          result.push(matchObject(v, b[k]));
        } else {
          if ((v != null) && (b[k] !== v)) {
            logger.log(`lambda configuration mismatch: ${k}:${b[k]} should be ${v}`);
            result.push(needsUpdating = true);
          } else {
            result.push(undefined);
          }
        }
      }
      return result;
    })();
  };

  return makeLambdaConfiguration(context, logger)
  .then(function(lambdaConfig) {
    matchObject(lambdaConfig, lambdaContext.deployedLambdaConfig);

    if (!needsUpdating) {
      return Promise.resolve();
    }

    logger.log("patching Lambda configuration");

    const params =
      {FunctionName: context.lambdaName};

    for (let k in lambdaConfig) {
      const v = lambdaConfig[k];
      params[k] = v;
    }

    return lambdaContext.lambda.updateFunctionConfiguration(params).promise();
  });
};


var updateLambdaCode = function(context, logger, lambdaContext) {
  // todo: with node_modules it's much easier to get bigger than
  // updateFunctionCode supports... will have to go through S3 then?

  if (lambdaContext.deployedSHA256 === lambdaContext.zipSHA256) {
    logger.log(`Lambda function ${context.lambdaName} code already up to date`);
    return Promise.resolve();
  }

  logger.log(`updating code for Lambda function ${context.lambdaName}`);

  const params = {
    FunctionName: context.lambdaName,
    Publish: true,
    ZipFile: fs.readFileSync(lambdaContext.zipFilename)
  };

  return lambdaContext.lambda.updateFunctionCode(params).promise()
  .then(data => context.localCache.storeHash('lambdaSHA256', data.CodeSha256));
};


var checkLambdaQualifier = function(context, logger, lambdaContext) {
  let params = {
    FunctionName: context.lambdaName,
    Name: lambdaContext.qualifier
  };

  return lambdaContext.lambda.getAlias(params).promise()
  .catch(function(err) {
    if (err.code === "ResourceNotFoundException") {
      // not found is fine, we'll make it
      params = {
        FunctionName: context.lambdaName,
        Name: lambdaContext.qualifier,
        Description: "Auto created by Litexa",
        FunctionVersion: "$LATEST"
      };
      return lambdaContext.lambda.createAlias(params).promise()
      .catch(function(err) {
        logger.error(err);
        throw `Failed to create alias ${lambdaContext.qualifier}`;
        throw new Error(`Failed to create alias ${lambdaContext.qualifier}`);}).then(function(data) {
        logger.verbose('createAlias', data);
        return Promise.resolve(data);
      });
    } else {
      logger.error(err);
      throw `Failed to fetch alias for lambda ${context.lambdaName}, ${lambdaContext.qualifier}`;
      return Promise.resolve();
    }}).then(function(data) {
    // the development head should always be latest
    if (data.FunctionVersion === '$LATEST') {
      return Promise.resolve();
    }

    params = {
      RevisionId: data.RevisionId,
      FunctionName: context.lambdaName,
      Name: lambdaContext.qualifier,
      Description: "Auto created by Litexa",
      FunctionVersion: "$LATEST"
    };

    return lambdaContext.lambda.updateAlias(params).promise();
  });
};


var checkLambdaPermissions = function(context, logger, lambdaContext) {
  if (context.localCache.timestampExists(`lambdaPermissionsChecked-${lambdaContext.qualifier}`)) {
    return Promise.resolve();
  }

  const addPolicy = function(cache) {
    logger.log(`adding policies to Lambda ${context.lambdaName}`);
    const params = {
      FunctionName: context.lambdaName,
      Action: 'lambda:InvokeFunction',
      StatementId: 'lc-' + uuid.v4(),
      Principal: 'alexa-appkit.amazon.com',
      Qualifier: lambdaContext.qualifier
    };

    return lambdaContext.lambda.addPermission(params).promise()
    .catch(err => logger.error(`Failed to add permissions to lambda: ${err}`)).then(data => logger.verbose(`addPermission: ${JSON.stringify(data, null, 2)}`));
  };

  const removePolicy = function(statement) {
    logger.log(`removing policy ${statement.Sid} from lambda ${context.lambdaName}`);
    const params = {
      FunctionName: context.lambdaName,
      StatementId: statement.Sid,
      Qualifier: lambdaContext.qualifier
    };

    return lambdaContext.lambda.removePermission(params).promise()
    .catch(function(err) {
      logger.error(err);
      throw "failed to remove bad lambda permission";
    });
  };

  logger.log("pulling existing policies");

  const params = {
    FunctionName: context.lambdaName,
    Qualifier: lambdaContext.qualifier
  };

  return lambdaContext.lambda.getPolicy(params).promise()
  .catch(function(err) {
    // ResourceNotFoundException is fine, might not have a policy
    if (err.code !== "ResourceNotFoundException") {
      logger.error(err);
      throw `Failed to fetch policies for lambda ${context.lambdaName}`;
    }}).then(function(data) {
    const promises = [];
    let foundCorrectPolicy = false;
    if (data != null) {
      logger.log("reconciling policies against existing data");
      // analyze the existing one
      const policy = JSON.parse(data.Policy);
      for (let statement of Array.from(policy.Statement)) {
        // is this the ask statement?
        if ((statement.Principal != null ? statement.Principal.Service : undefined) !== "alexa-appkit.amazon.com") { continue; }
        // still the right contents?
        const lambdaARN = context.artifacts.get('lambdaARN');
        if ((lambdaARN != null) &&
            (statement.Resource === lambdaARN) &&
            (statement.Effect === 'Allow') &&
            (statement.Action === 'lambda:InvokeFunction')) {
          foundCorrectPolicy = true;
        } else {
          promises.push(removePolicy(statement));
        }
      }
    }

    if (!foundCorrectPolicy) {
      promises.push(addPolicy());
    }

    return Promise.all(promises)
    .then(() => context.localCache.saveTimestamp(`lambdaPermissionsChecked-${lambdaContext.qualifier}`));
  });
};


var endLambdaDeployment = function(context, logger, lambdaContext) {
  const deltaTime = (new Date) - context.lambdaDeployStart;
  logger.log(`lambda deployment complete in ${deltaTime}ms`);
  return context.localCache.saveTimestamp('lambdaUpdated');
};


var ensureDynamoTable = function(context, logger, lambdaContext) {
  context.dynamoTableName = [
    context.projectInfo.name,
    context.projectInfo.variant,
    "litexa_handler_state"
  ].join('_');

  // if its existence is already verified, no need to do so anymore
  if (context.localCache.timestampExists('ensuredDynamoTable')) {
    return Promise.resolve();
  }

  const dynamo = new AWS.DynamoDB({
    params: {
      TableName: context.dynamoTableName
    }
  });

  logger.log("fetching dynamoDB information");
  return dynamo.describeTable({}).promise()
  .catch(function(err) {
    if (err.code !== 'ResourceNotFoundException') {
      logger.error(err);
      throw "failed to ensure dynamoDB table exists";
    }

    logger.log(`dynamoDB table not found, creating ${context.dynamoTableName}`);
    const params = {
      AttributeDefinitions: [
        {
          AttributeName: "userId",
          AttributeType: "S"
        }
      ],
      KeySchema: [
        {
          AttributeName: "userId",
          KeyType: "HASH"
        }
      ],
      ProvisionedThroughput: {
        ReadCapacityUnits: 10,
        WriteCapacityUnits: 10
      }
    };

    return dynamo.createTable(params).promise()
    .then(function() {
      context.localCache.saveTimestamp('createdDynamoTable');
      return dynamo.describeTable({}).promise();
    });}).then(function(data) {
    logger.log("verified dynamoDB table exists");
    context.dynamoTableARN = data.Table.TableArn;
    context.artifacts.save('dynamoDBARN', data.Table.TableArn);
    return context.localCache.saveTimestamp('ensuredDynamoTable');
  });
};


// only modify the retention policy if it's creating an new log group
var changeCloudwatchRetentionPolicy = function(context, logger, lambdaContext) {
  if (context.localCache.timestampExists('ensuredCloudwatchLogGroup')) {
    return Promise.resolve();
  }
  const logGroupName = `/aws/lambda/${context.lambdaName}`;
  const cloudwatch = new AWS.CloudWatchLogs();
  let params = {
    logGroupNamePrefix: logGroupName
  };
  return cloudwatch.describeLogGroups(params).promise()
  .then(function(data) {
    let logGroupExists = false;
    for (let logGroup of Array.from(data.logGroups)) {
      if (logGroup.logGroupName === logGroupName) {
        logGroupExists = true;
        break;
      }
    }

    if (logGroupExists) {
      context.localCache.saveTimestamp('ensuredCloudwatchLogGroup');
      return Promise.resolve();
    }

    params = { logGroupName };
    return cloudwatch.createLogGroup(params).promise()
    .then(function() {
      logger.log("Created Cloudwatch log group for lambda");
      params = {
        logGroupName,
        retentionInDays: 30
      };
      context.localCache.saveTimestamp('ensuredCloudwatchLogGroup');

      return cloudwatch.putRetentionPolicy(params).promise()
      .then(function() {
        logger.log("Updated CloudWatch retention policy to 30 days");
        context.localCache.saveTimestamp('appliedLogRetentionPolicy');
        return Promise.resolve();
      });
    });
  });
};

function checkForAssetsRoot(context, logger, lambdaContext) {
  if (!context.artifacts.get('assets-root')) {
    return logger.warning('WARNING: Assets root is not set in the deployed lambda environment configuration.');
  }
};

export default {
  unitTestHelper,
  deploy
};
